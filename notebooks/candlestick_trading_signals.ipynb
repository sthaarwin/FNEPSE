{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70cceb10",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca6179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model # type: ignore\n",
    "from tensorflow.keras import layers, models #type: ignore\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa169c",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63fb666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw OHLC data\n",
    "df = pd.read_csv(\"../data/raw/merged-stock-data.csv\")\n",
    "print(\"Available columns:\", df.columns.tolist())\n",
    "print(f\"Initial data shape: {df.shape}\")\n",
    "\n",
    "# Use ORIGINAL technical features (to match your trained model)\n",
    "def add_technical_features(df):\n",
    "    \"\"\"Add original technical indicators (10 features total)\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Original features - keep exactly the same as training\n",
    "    df['ma_5'] = df['close'].rolling(5).mean()\n",
    "    df['ma_20'] = df['close'].rolling(20).mean()\n",
    "    df['price_change'] = df['close'].pct_change()\n",
    "    df['volatility'] = df['close'].rolling(10).std()\n",
    "    df['hl_spread'] = (df['high'] - df['low']) / df['close']\n",
    "    df['oc_spread'] = (df['close'] - df['open']) / df['open']\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "# Use ORIGINAL feature columns (exactly 10 features)\n",
    "feature_cols = [\n",
    "    \"open\", \"high\", \"low\", \"close\",           # OHLC (4 features)\n",
    "    \"ma_5\", \"ma_20\",                          # Moving averages (2 features)\n",
    "    \"price_change\", \"volatility\",             # Price dynamics (2 features)\n",
    "    \"hl_spread\", \"oc_spread\"                  # Spreads (2 features)\n",
    "]                                             # Total: 10 features\n",
    "\n",
    "print(\"Adding technical features...\")\n",
    "df = add_technical_features(df)\n",
    "print(f\"Features used: {len(feature_cols)} features (matches trained model)\")\n",
    "print(f\"Data shape after feature engineering: {df.shape}\")\n",
    "\n",
    "x_raw = df[feature_cols].values\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "x_scaled = scaler.fit_transform(x_raw)\n",
    "print(\"Features scaled successfully\")\n",
    "print(f\"Scaled features shape: {x_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41febc13",
   "metadata": {},
   "source": [
    "# 3. Load Saved Pattern Recognition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aafdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_model = load_model(\"../models/candlestick_cnn_lstm.h5\")\n",
    "\n",
    "lookback = 20\n",
    "\n",
    "x_seq = []\n",
    "for i in range(lookback, len(x_scaled)):\n",
    "    x_seq.append(x_scaled[i-lookback:i])\n",
    "\n",
    "x_seq = np.array(x_seq)\n",
    "\n",
    "patterns_preds = np.argmax(pattern_model.predict(x_seq), axis=1)\n",
    "print(\"predicted pattern shape : \", patterns_preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d86360",
   "metadata": {},
   "source": [
    "# 4. Create Trading Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2072716",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = df[\"close\"].pct_change().values\n",
    "returns = returns[lookback:]    \n",
    "\n",
    "# Use exact percentiles for balanced classification\n",
    "buy_threshold = np.percentile(returns, 70)   # Top 30% = Buy\n",
    "sell_threshold = np.percentile(returns, 30)  # Bottom 30% = Sell\n",
    "\n",
    "y_trading = np.ones(len(returns), dtype=int)  # Default to Hold (1)\n",
    "y_trading[returns > buy_threshold] = 2       # Buy signal\n",
    "y_trading[returns < sell_threshold] = 0      # Sell signal\n",
    "\n",
    "print(\"Balanced Trading Labels Distribution:\")\n",
    "print(f\"Sell (0): {np.sum(y_trading == 0)} ({np.sum(y_trading == 0)/len(y_trading)*100:.1f}%)\")\n",
    "print(f\"Hold (1): {np.sum(y_trading == 1)} ({np.sum(y_trading == 1)/len(y_trading)*100:.1f}%)\")\n",
    "print(f\"Buy (2): {np.sum(y_trading == 2)} ({np.sum(y_trading == 2)/len(y_trading)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nReturn thresholds:\")\n",
    "print(f\"Buy threshold (70th percentile): {buy_threshold*100:.3f}%\")\n",
    "print(f\"Sell threshold (30th percentile): {sell_threshold*100:.3f}%\")\n",
    "print(f\"Mean return: {np.mean(returns)*100:.3f}%\")\n",
    "print(f\"Std return: {np.std(returns)*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af405af9",
   "metadata": {},
   "source": [
    "# 5. Combine Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2f8729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting pattern predictions to one-hot\n",
    "\n",
    "num_patterns = np.max(patterns_preds) + 1\n",
    "pattern_onehot = np.eye(num_patterns)[patterns_preds]\n",
    "\n",
    "#combine OHLC sequences with patterns\n",
    "#flatten sequences + pattern for MLP inputs\n",
    "x_trading = x_seq.reshape(x_seq.shape[0], -1)\n",
    "x_trading = np.hstack([x_trading, pattern_onehot])\n",
    "\n",
    "print(\"Trading features shape : \", x_trading)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbaf487",
   "metadata": {},
   "source": [
    "# 6. Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f403e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_trading, y_trading, test_size=0.2, shuffle=False)\n",
    "\n",
    "print(\"Training set shape:\", x_train.shape)\n",
    "print(\"Test set shape:\", x_test.shape)\n",
    "print(\"Training labels distribution:\", np.bincount(y_train))\n",
    "print(\"Test labels distribution:\", np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d9014d",
   "metadata": {},
   "source": [
    "# 7. Build Trading Signal Model (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f3de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_train.shape[1]\n",
    "num_classes = 3\n",
    "\n",
    "inputs = layers.Input(shape=(input_shape,))\n",
    "\n",
    "x = layers.Dense(128, activation=\"relu\")(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "trading_model = models.Model(inputs, outputs)\n",
    "\n",
    "trading_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "trading_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2328a14",
   "metadata": {},
   "source": [
    "# 8. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5066dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Compute class weights to handle imbalance\n",
    "class_weights = compute_class_weight('balanced', \n",
    "                                   classes=np.unique(y_train), \n",
    "                                   y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True, monitor='val_accuracy'),\n",
    "    ReduceLROnPlateau(patience=3, factor=0.5, monitor='val_accuracy', verbose=1)\n",
    "]\n",
    "\n",
    "history = trading_model.fit(\n",
    "    x_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=30,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3148a9",
   "metadata": {},
   "source": [
    "# 9. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331bb61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Basic evaluation\n",
    "test_loss, test_accuracy = trading_model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Detailed predictions\n",
    "y_pred = trading_model.predict(x_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes, \n",
    "                          target_names=['Sell', 'Hold', 'Buy']))\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Sell', 'Hold', 'Buy'],\n",
    "            yticklabels=['Sell', 'Hold', 'Buy'])\n",
    "plt.title('Trading Signal Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2f2d22",
   "metadata": {},
   "source": [
    "# 10. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c373f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Val Accuracy\")\n",
    "plt.xlabel(\"Epoches\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
